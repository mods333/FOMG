{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "from collections import Counter\n",
    "from random import random\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \n",
    "    def __init(self,network_class,*args):\n",
    "        \n",
    "        #define the network for the learner and the meta-learner network\n",
    "        self.meta_net = network_class(*args)\n",
    "        self.learner_net = network_class(*args)\n",
    "        \n",
    "        self.optimizer = optim.SGD(self.learner_net.parameters(), 0.1)\n",
    "        \n",
    "    \n",
    "    def copy_theta(self):\n",
    "        \n",
    "        self.learner_net.load_state_dict(self.meta_net.state_dict())\n",
    "        \n",
    "    def forward(self, support_x, support_y, query_x, query_y,num_updates):\n",
    "        \n",
    "        #Copy theta into theta'\n",
    "        self.copy_theta()\n",
    "        \n",
    "        # update for several steps\n",
    "        for i in range(num_updates):\n",
    "            # forward and backward to update net_pi grad.\n",
    "            loss, pred = self.learner_net(support_x, support_y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        #Find the loss on the query set\n",
    "        loss, pred = self.learner_net(query_x, query_y)\n",
    "        # pred: [setsz, n_way], indices: [setsz]\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "        correct = torch.eq(indices, query_y).sum().data[0]\n",
    "        acc = correct / query_y.size(0)\n",
    "\n",
    "        grads_pi = autograd.grad(loss, self.learner_net.parameters(), create_graph=True)\n",
    "\n",
    "        return loss, grads_pi, acc\n",
    "\n",
    "    def net_forward(self, support_x, support_y):\n",
    "        \n",
    "        loss, pred = self.net(support_x, support_y)\n",
    "        return loss, pred              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    \n",
    "    def __init(self,network_class,network_args,k_shot,beta,num_updates):\n",
    "        \n",
    "        super(MetaLearner, self).__init__()\n",
    "\n",
    "        self.k_shot = k_shot\n",
    "        self.beta = beta\n",
    "        self.num_updates = num_updates\n",
    "\n",
    "        # it will contains a learner class to learn on episodes and gather the loss together.\n",
    "        self.learner = Learner(network_class, *net_cls_args)\n",
    "        # the optimizer is to update theta parameters, not theta_pi parameters.\n",
    "        self.optimizer = optim.Adam(self.learner.parameters(), lr=beta)\n",
    "        \n",
    "    def write_grads(self, dummy_loss, sum_grads_pi):\n",
    "        \"\"\"\n",
    "        write loss into learner.net, gradients come from sum_grads_pi.\n",
    "        Since the gradients info is not calculated by general backward, we need this function to write the right gradients\n",
    "        into theta network and update theta parameters as wished.\n",
    "        :param dummy_loss: dummy loss, nothing but to write our gradients by hook\n",
    "        :param sum_grads_pi: the summed gradients\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Register a hook on each parameter in the net that replaces the current dummy grad\n",
    "        # with our grads accumulated across the meta-batch\n",
    "        hooks = []\n",
    "\n",
    "        for i, v in enumerate(self.learner.parameters()):\n",
    "            def closure():\n",
    "                ii = i\n",
    "                return lambda grad: sum_grads_pi[ii]\n",
    "\n",
    "            # if you write: hooks.append( v.register_hook(lambda grad : sum_grads_pi[i]) )\n",
    "            # it will pop an ERROR, i don't know why?\n",
    "            hooks.append(v.register_hook(closure()))\n",
    "\n",
    "        # use our sumed gradients_pi to update the theta/net network,\n",
    "        # since our optimizer receive the self.net.parameters() only.\n",
    "        self.optimizer.zero_grad()\n",
    "        dummy_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # if you do NOT remove the hook, the GPU memory will expode!!!\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "    def forward(self, support_x, support_y, query_x, query_y):\n",
    "        \n",
    "        sum_grads_pi = None\n",
    "        meta_batchsz = support_y.size(0)\n",
    "\n",
    "        # support_x[i]: [setsz, c_, h, w]\n",
    "        # we do different learning task sequentially, not parallel.\n",
    "        accs = []\n",
    "        # for each task/episode.\n",
    "        for i in range(meta_batchsz):\n",
    "            _, grad_pi, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates)\n",
    "            accs.append(episode_acc)\n",
    "            if sum_grads_pi is None:\n",
    "                sum_grads_pi = grad_pi\n",
    "            else:  # accumulate all gradients from different episode learner\n",
    "                sum_grads_pi = [torch.add(i, j) for i, j in zip(sum_grads_pi, grad_pi)]\n",
    "\n",
    "        # As we already have the grads to update\n",
    "        # We use a dummy forward / backward pass to get the correct grads into self.net\n",
    "        # the right grads will be updated by hook, ignoring backward.\n",
    "        # use hook mechnism to write sumed gradient into network.\n",
    "        # we need to update the theta/net network, we need a op from net network, so we call self.learner.net_forward\n",
    "        # to get the op from net network, since the loss from self.learner.forward will return loss from net_pi network.\n",
    "        dummy_loss, _ = self.learner.net_forward(support_x[0], support_y[0])\n",
    "        self.write_grads(dummy_loss, sum_grads_pi)\n",
    "\n",
    "        return accs\n",
    "    \n",
    "    def pred(self, support_x, support_y, query_x, query_y):\n",
    "        \"\"\"\n",
    "        predict for query_x\n",
    "        :param support_x:\n",
    "        :param support_y:\n",
    "        :param query_x:\n",
    "        :param query_y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        meta_batchsz = support_y.size(0)\n",
    "\n",
    "        accs = []\n",
    "        # for each task/episode.\n",
    "        # the learner will copy parameters from current theta network and then fine-tune on support set.\n",
    "        for i in range(meta_batchsz):\n",
    "            _, _, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates)\n",
    "            accs.append(episode_acc)\n",
    "\n",
    "        return np.array(accs).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
