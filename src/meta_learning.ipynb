{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Some global variables \"\"\"\n",
    "_loader = Loader(502) # 500 + SOS + EOS\n",
    "loader = MIDILoader(_loader)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# Is the tokenizer 1 indexed?\n",
    "vocabulary_size = 16*128*2 + 32*16 + 100 + 1 # 4708 + 1\n",
    "vocabulary_size = vocabulary_size + 2 # SOS (index 4709) and EOS (index 4710)\n",
    "SOS_TOKEN = 4709\n",
    "EOS_TOKEN = 4710\n",
    "\n",
    "encoding_size = 500\n",
    "one_hot_embeddings = np.eye(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "        \n",
    "    def forward(self, input, hidden_in):\n",
    "        _, hidden_out = self.lstm(input, hidden_in) # encoder only outputs hidden\n",
    "        return hidden_out\n",
    "    \n",
    "    def initHidden(self, hidden, batch_size):\n",
    "        \n",
    "        if hidden == None:\n",
    "            result = Variable(torch.zeros(1, batch_size, self.hidden_size)).double()\n",
    "            \n",
    "            if use_cuda:\n",
    "                result = result.cuda()\n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        self.out = nn.Linear(hidden_size, output_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.out = self.out.cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = output.squeeze()\n",
    "        return output.unsqueeze(0), hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(1, batch_size, self.hidden_size)).double()\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next two functions are part of some other deep learning frameworks, but PyTorch\n",
    "# has not yet implemented them. We can find some commonly-used open source worked arounds\n",
    "# after searching around a bit: https://gist.github.com/jihunchoi/f1434a77df9db1bb337417854b398df1.\n",
    "def _sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def compute_loss(logits, target, length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = F.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = _sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.double()\n",
    "    loss = losses.sum() / length.double().sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size):\n",
    "        super(MetaLearner,self).__init__()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 learning_rate,\n",
    "                 embeddings=one_hot_embeddings):\n",
    "        \n",
    "        super(Learner,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = EncoderLSTM(input_size, hidden_size)\n",
    "        self.decoder = DecoderLSTM(input_size, hidden_size, output_size)\n",
    "        self.encoder_optimizer = torch.optim.Adam(self.encoder.parameters(), lr=learning_rate)\n",
    "        self.decoder_optimizer = torch.optim.Adam(self.decoder.parameters(), lr=learning_rate)\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    \n",
    "    def forward(self, sequence, numbered_seq, hidden):\n",
    "        \n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "        embeddings = self.embeddings\n",
    "        criterion = self.criterion\n",
    "        \n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        seq_size = sequence.size()\n",
    "        batch_size = seq_size[1]\n",
    "        sequence_length = seq_size[0]\n",
    "        loss = 0\n",
    "        \n",
    "        # h_n = (1, batch_size, encoding_size)\n",
    "        encoder_hidden = encoder.initHidden(hidden, batch_size)\n",
    "        encoder_hidden = (encoder_hidden, encoder_hidden) # Need a tuple\n",
    "\n",
    "        # Encoder is fed the flipped control sequence\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[index_control].unsqueeze(0) # (1, batch_size, vocab_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "        \n",
    "        # feed encoder_hidden\n",
    "        decoder_input = sequence[1].unsqueeze(0) # One after SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        predicted_note_index = 0\n",
    "        \n",
    "        # Prepare the results tensor\n",
    "        all_decoder_outputs = Variable(torch.zeros(*sequence.size())).double() # (seq_length, batch_size, vocab_size)\n",
    "        if use_cuda:\n",
    "            all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "        all_decoder_outputs[0] = decoder_input\n",
    "\n",
    "        for index_control in range(2, sequence_length):\n",
    "            # decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "            if random.random() <= 0.9:\n",
    "                decoder_input = sequence[index_control].unsqueeze(0)\n",
    "            else:\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                # This is the next input, without teacher forcing it's the predicted output\n",
    "                decoder_input = torch.stack([Variable(torch.DoubleTensor(embeddings[ni]))\n",
    "                                         for ni in topi.squeeze()]).unsqueeze(0)\n",
    "                if use_cuda:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "                    \n",
    "            # Save the decoder output\n",
    "            all_decoder_outputs[index_control] = decoder_output\n",
    "        \n",
    "        \n",
    "        seq_lens = Variable(torch.LongTensor(np.ones(batch_size, dtype=int)*sequence_length))\n",
    "        if use_cuda:\n",
    "            seq_lens = seq_lens.cuda()\n",
    "        loss = compute_loss(all_decoder_outputs.transpose(0,1).contiguous(),\n",
    "                        numbered_seq.transpose(0,1).contiguous(), \n",
    "                        seq_lens)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def map_inference(self, sequence, hidden, embeddings=one_hot_embeddings, max_length=500):\n",
    "        \"\"\" sequence has to be batch_size=1\"\"\"\n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "        \n",
    "        output_control_sequence = []\n",
    "    \n",
    "        # Encoder\n",
    "        encoder_hidden = encoder.initHidden(hidden, batch_size=1)\n",
    "        encoder_hidden = (encoder_hidden, encoder_hidden)\n",
    "\n",
    "        sequence_length = sequence.size()[1]\n",
    "\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input\n",
    "\n",
    "        # This point we have last encoder_hidden, feed into decoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = sequence[0][0]\n",
    "        predicted_control_index = SOS_TOKEN\n",
    "\n",
    "        cur_length = 0\n",
    "        while True:\n",
    "            decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # MAP inference\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            predicted_control_index = int(topi)\n",
    "            if predicted_control_index == EOS_TOKEN:\n",
    "                break\n",
    "            output_control_sequence.append(predicted_control_index)\n",
    "\n",
    "            # This is the next input\n",
    "            decoder_input = torch.from_numpy(embeddings[predicted_control_index])\n",
    "            decoder_input = Variable(decoder_input).double()\n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            cur_length += 1\n",
    "            if cur_length >= max_length:\n",
    "                break\n",
    "\n",
    "        return output_control_sequence\n",
    "    \n",
    "    def train(self, sequence, numbered_seq, hidden):\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.forward(sequence, numbered_seq, hidden)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        return loss\n",
    "\n",
    "learner = Learner(vocabulary_size, \n",
    "              encoding_size, \n",
    "              vocabulary_size,\n",
    "              learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_files = ['bach_846.mid', 'mz_311_1.mid', 'rac_op3_2.mid']\n",
    "input_variables = []\n",
    "original_sequences = []\n",
    "\n",
    "for index, input_file in enumerate(input_files):\n",
    "    orig_seq = loader.read('../data/' + input_file)\n",
    "    orig_seq = loader.tokenize(orig_seq)\n",
    "    \n",
    "    trunc_seq = orig_seq[0:500]\n",
    "    trunc_seq = [SOS_TOKEN] + trunc_seq + [EOS_TOKEN]\n",
    "    original_sequences.append(trunc_seq)\n",
    "    seq_length = len(trunc_seq)\n",
    "    \n",
    "    trunc_seq = torch.from_numpy(np.array(one_hot_embeddings[trunc_seq])) # This is really time consuming\n",
    "    trunc_seq = trunc_seq.view(seq_length, vocabulary_size)\n",
    "    trunc_seq = Variable(trunc_seq)\n",
    "    if use_cuda:\n",
    "        trunc_seq = trunc_seq.cuda()\n",
    "    input_variables.append(trunc_seq)\n",
    "    \n",
    "original_sequences = np.array(original_sequences, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4709  4709\n",
      " 4144  4143\n",
      "  188   194\n",
      "     â‹®      \n",
      " 2243  2255\n",
      "  200  4611\n",
      " 4710  4710\n",
      "[torch.LongTensor of size 502x2]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4dac28ea4dbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mnumbered_seqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumbered_seqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbered_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7c7eef9a520d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sequence, numbered_seq, hidden)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbered_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Testing Learner \"\"\"\n",
    "print_every = 10\n",
    "total_epochs = 200\n",
    "print_loss_total = 0\n",
    "batch_size = 2\n",
    "startTime = time.time()\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    for batch in range(len(input_variables)//batch_size):\n",
    "        # lstm input is (seq_len, batch_size, vocab_size)\n",
    "        start, end = batch*batch_size, (batch+1)*batch_size\n",
    "        sequences = torch.stack(input_variables[start:end]).transpose(0,1)\n",
    "        numbered_seqs = torch.stack(Variable(torch.from_numpy(original_sequences[start:end]))).transpose(0,1)\n",
    "        print(numbered_seqs)\n",
    "        if use_cuda:\n",
    "            numbered_seqs = numbered_seqs.cuda()\n",
    "        loss = learner.train(sequences, numbered_seqs, hidden=None)\n",
    "        print_loss_total += loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(startTime, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_index = 0\n",
    "test_seq = input_variables[song_index][:,1:101] # First dimension is batch\n",
    "out_seq = learner.map_inference(test_seq, hidden=None)\n",
    "whole_seq = original_sequences[song_index][0:100].tolist() + out_seq\n",
    "midi = loader.detokenize(np.array(whole_seq))\n",
    "midi.write('test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.cuda.DoubleTensor of size 1x2x500 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_hidden = learner.encoder.initHidden(None).squeeze()\n",
    "print(torch.stack([test_hidden, test_hidden]).unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
