{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Some global variables \"\"\"\n",
    "_loader = Loader(500)\n",
    "loader = MIDILoader(_loader)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# Is the tokenizer 1 indexed?\n",
    "vocabulary_size = 16*128*2 + 32*16 + 100 + 1 # 4708 + 1\n",
    "vocabulary_size = vocabulary_size + 2 # SOS (index 4709) and EOS (index 4710)\n",
    "SOS_TOKEN = 4709\n",
    "EOS_TOKEN = 4710\n",
    "\n",
    "encoding_size = 500\n",
    "one_hot_embeddings = np.eye(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "        \n",
    "    def forward(self, input, hidden_in):\n",
    "        _, hidden_out = self.lstm(input, hidden_in) # encoder only outputs hidden\n",
    "        return hidden_out\n",
    "    \n",
    "    def initHidden(self, hidden):\n",
    "        \n",
    "        if hidden == None:\n",
    "            result = Variable(torch.zeros(1, 1, self.hidden_size)).double()\n",
    "            \n",
    "            if use_cuda:\n",
    "                result = result.cuda()\n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        self.out = nn.Linear(hidden_size, output_size).double()\n",
    "        self.project = nn.Linear(4096, self.hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.out = self.out.cuda()\n",
    "            self.project = self.project.cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = output.squeeze()\n",
    "        return output.unsqueeze(0), hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size)).double()\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size):\n",
    "        super(MetaLearner,self).__init__()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 learning_rate,\n",
    "                 embeddings=one_hot_embeddings):\n",
    "        \n",
    "        super(Learner,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = EncoderLSTM(input_size, hidden_size)\n",
    "        self.decoder = DecoderLSTM(input_size, hidden_size, output_size)\n",
    "        self.encoder_optimizer = torch.optim.Adam(self.encoder.parameters(), lr=learning_rate)\n",
    "        self.decoder_optimizer = torch.optim.Adam(self.decoder.parameters(), lr=learning_rate)\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    \n",
    "    def forward(self, sequence, hidden):\n",
    "        \n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "        embeddings = self.embeddings\n",
    "        criterion = self.criterion\n",
    "        \n",
    "        sequence_length = sequence.size()[1]\n",
    "        loss = 0\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(hidden)\n",
    "        encoder_hidden = (encoder_hidden, encoder_hidden) # Need a tuple\n",
    "\n",
    "        # Encoder is fed the flipped control sequence\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input  \n",
    "        \n",
    "        # feed encoder_hidden\n",
    "        decoder_input = sequence[0][1] # One after SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        predicted_note_index = 0\n",
    "\n",
    "        for index_control in range(2, sequence_length):\n",
    "            decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            predicted_control_index = int(topi)\n",
    "            \n",
    "            if random.random() <= 0.9:\n",
    "                decoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            else:\n",
    "                # This is the next input, without teacher forcing it's the predicted output\n",
    "                decoder_input = torch.from_numpy(embeddings[predicted_control_index])\n",
    "                decoder_input = Variable(decoder_input)\n",
    "                if use_cuda:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "                    \n",
    "            # CrossEntropyLoss takes input1: (N, C) and input2: (N).\n",
    "            _, actual_control_index = sequence[0][index_control].topk(1)\n",
    "            if use_cuda:\n",
    "                actual_control_index = actual_control_index.cuda()\n",
    "            loss += criterion(decoder_output, actual_control_index)\n",
    "            \n",
    "        return loss / index_control\n",
    "    \n",
    "    def map_inference(self, sequence, hidden, embeddings=one_hot_embeddings, max_length=500):\n",
    "        \n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "        \n",
    "        output_control_sequence = []\n",
    "    \n",
    "        # Encoder\n",
    "        encoder_hidden = encoder.initHidden(hidden)\n",
    "        encoder_hidden = (encoder_hidden, encoder_hidden)\n",
    "\n",
    "        sequence_length = sequence.size()[1]\n",
    "\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input\n",
    "\n",
    "        # This point we have last encoder_hidden, feed into decoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = sequence[0][0]\n",
    "        predicted_control_index = SOS_TOKEN\n",
    "\n",
    "        cur_length = 0\n",
    "        while True:\n",
    "            decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # MAP inference\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            predicted_control_index = int(topi)\n",
    "            if predicted_control_index == EOS_TOKEN:\n",
    "                break\n",
    "            output_control_sequence.append(predicted_control_index)\n",
    "\n",
    "            # This is the next input\n",
    "            decoder_input = torch.from_numpy(embeddings[predicted_control_index])\n",
    "            decoder_input = Variable(decoder_input).double()\n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            cur_length += 1\n",
    "            if cur_length >= max_length:\n",
    "                break\n",
    "\n",
    "        return output_control_sequence\n",
    "    \n",
    "    def train(self, sequence, hidden):\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.forward(sequence, hidden)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        return loss\n",
    "\n",
    "learner = Learner(vocabulary_size, \n",
    "              encoding_size, \n",
    "              vocabulary_size,\n",
    "              learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ['bach_846.mid']\n",
    "input_variables = []\n",
    "original_sequences = []\n",
    "\n",
    "for index, input_file in enumerate(input_files):\n",
    "    orig_seq = loader.read('../data/' + input_file)\n",
    "    orig_seq = loader.tokenize(orig_seq)\n",
    "    \n",
    "    trunc_seq = orig_seq[0:500]\n",
    "    original_sequences.append(trunc_seq)\n",
    "    trunc_seq = [SOS_TOKEN] + trunc_seq + [EOS_TOKEN]\n",
    "    seq_length = len(trunc_seq)\n",
    "    \n",
    "    trunc_seq = torch.from_numpy(np.array(one_hot_embeddings[trunc_seq])) # This is really time consuming\n",
    "    trunc_seq = trunc_seq.view(1, seq_length, vocabulary_size)\n",
    "    trunc_seq = Variable(trunc_seq)\n",
    "    if use_cuda:\n",
    "        trunc_seq = trunc_seq.cuda()\n",
    "    input_variables.append(trunc_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 52s (- 35m 34s) (10 5%) 2.5466\n",
      "3m 44s (- 33m 43s) (20 10%) 1.9183\n",
      "5m 36s (- 31m 48s) (30 15%) 1.3655\n",
      "7m 30s (- 30m 2s) (40 20%) 0.9520\n",
      "9m 23s (- 28m 9s) (50 25%) 0.6633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0733e2a23583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-c25c126d318c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sequence, hidden)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Testing Learner \"\"\"\n",
    "print_every = 10\n",
    "total_epochs = 200\n",
    "print_loss_total = 0\n",
    "start = time.time()\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    for index, sequence in enumerate(input_variables):\n",
    "        loss = learner.train(sequence, hidden=None)\n",
    "        print_loss_total += loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_index = 0\n",
    "test_seq = input_variables[song_index][:,1:101] # First dimension is batch\n",
    "out_seq = learner.map_inference(test_seq, hidden=None)\n",
    "whole_seq = original_sequences[song_index][0:100] + out_seq\n",
    "midi = loader.detokenize(np.array(whole_seq))\n",
    "midi.write('test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4144, 188, 4628, 4143, 192, 4629, 4142, 195, 4628, 2243, 4143, 200, 4628, 2248, 4144, 204, 4626, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4629, 2248, 204, 4628, 2236, 2252, 4144, 188, 4628, 2240, 4143, 192, 4628, 4142, 195, 4629, 2243, 4143, 200, 4628, 2248, 4144, 204, 4626, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4145, 188, 4610, 2240, 4627, 4143, 190, 4628, 4142, 197, 4628, 2245, 4143, 202, 4628, 2250, 4145, 205, 4625, 2253, 4610, 4141, 197, 4628, 2245, 202, 4628, 2250, 205, 4627, 2236, 2253, 4145, 188, 4628, 2238, 4143, 190, 4628, 197, 4628, 2245, 202, 4627, 2250, 4145, 205, 4625, 2253, 4610, 4141, 197, 4628, 2245, 202, 4627, 2250, 205, 4629, 2253, 4145, 187, 4609, 2236, 2238, 4627, 4143, 190, 4628, 4142, 195, 4628, 2243, 4143, 202, 4627, 2250, 4145, 205, 4625, 2253, 4610, 4141, 195, 4628, 2243, 202, 4627, 2250, 205, 4628, 2235, 2253, 4145, 187, 4628, 2238, 4143, 190, 4628, 4142, 195, 4628, 2243, 4143, 202, 4628, 2250, 4145, 205, 4625, 2253, 4610, 4141, 195, 4628, 2243, 202, 4627, 2250, 205, 4629, 2253, 4144, 188, 4609, 2235, 2238, 4627, 4143, 192, 4628, 4142, 195, 4627, 2243, 200, 4628, 2248, 4143, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4628, 2240, 4143, 192, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4145, 188, 4609, 2240, 4627, 4144, 192, 4628, 197, 4628, 2245, 4145, 204, 4628, 2252, 4146, 209, 4625, 2257, 4610, 4142, 197, 4628, 2245, 4141, 204, 4627, 2252, 209, 4628, 2236, 2257, 4145, 188, 4628, 2240, 4144, 192, 4629, 197, 4628, 2245, 4145, 204, 4628, 2252, 209, 4625, 2257, 4610, 4142, 197, 4627, 2245, 4141, 204, 4628, 2252, 209, 4628, 2236, 2257, 4144, 188, 4609, 2240, 4627, 4143, 190, 4627, 4142, 194, 4628, 2242, 4143, 197, 4628, 2245, 4144, 202, 4625, 2250, 4610, 4141, 194, 4627, 2242, 4140, 197, 4628, 2245, 202, 4627, 2236, 2250, 4144, 188, 4628, 2238, 4143, 190, 4628, 4142, 194, 4628, 2242, 4143, 197, 4629, 2245, 4144, 202, 4625, 2250, 4610, 4141, 194, 4628, 2242, 4140, 197, 4627, 2245, 202, 4629, 2236, 2238, 2250, 4145, 187, 4628, 4143, 190, 4628, 195, 4628, 2243, 4144, 202, 4627, 2250, 4145, 207, 4626, 2255, 4609, 4141, 195, 4628, 2243, 202, 4627, 2250, 207, 4629, 2235, 2255, 4145, 187, 4628, 2238, 4143, 190, 4628, 195, 4628, 2243, 4144, 202, 4627, 2250, 4145, 207, 4625, 2255, 4610, 4141, 195, 4628, 2243, 202, 4627, 2250, 207, 4629, 2235, 2255, 4144, 187, 4610, 2238, 4626, 4143, 188, 4628, 4142, 192, 4628, 2240, 4143, 195, 4628, 2243, 4144, 200, 4626, 2248, 4610, 4141, 192, 4627, 2240, 4140, 195, 4627, 2243, 200, 4629, 2235, 2248, 4144, 187, 4627, 2236, 4143, 188, 4628, 4142, 192, 4627, 2240, 4143, 195, 4628, 2243, 4144, 200, 4626, 2248, 4609, 4141, 192, 4628, 2240, 4140, 195, 4627, 2243, 200]]\n",
      "[188, 4628, 4143, 192, 4629, 4142, 195, 4628, 2243, 4143, 200, 4628, 2248, 4144, 204, 4628, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4610, 4142, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4145, 188, 4628, 2240, 4143, 190, 4628, 4142, 195, 4628, 2243, 4143, 202, 4628, 2250, 4145, 205, 4625, 2253, 4610, 4141, 195, 4628, 2243, 202, 4627, 2250, 205, 4628, 2253, 4145, 188, 4609, 2236, 2238, 4627, 4143, 190, 4628, 4142, 195, 4628, 2243, 4143, 202, 4627, 2250, 4145, 207, 4625, 2255, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204, 4628, 2236, 2252, 4144, 188, 4609, 2240, 4627, 4143, 190, 4628, 4142, 195, 4627, 2243, 4143, 200, 4628, 2248, 4144, 204, 4625, 2252, 4610, 4141, 195, 4628, 2243, 4140, 200, 4628, 2248, 204]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
