{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "from collections import Counter\n",
    "from random import random\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "        \n",
    "    def forward(self, input, hidden_in):\n",
    "        _, hidden_out = self.lstm(input, hidden_in) # encoder only outputs hidden\n",
    "        return hidden_out\n",
    "    \n",
    "    def initHidden(self, hidden):\n",
    "        \n",
    "        if hidden == None:\n",
    "            result = Variable(torch.zeros(1, 1, self.hidden_size)).double()\n",
    "            \n",
    "            if use_cuda:\n",
    "                result = result.cuda()\n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        self.out = nn.Linear(hidden_size, output_size).double()\n",
    "        self.project = nn.Linear(4096, self.hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.out = self.out.cuda()\n",
    "            self.project = self.project.cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = output.squeeze()\n",
    "        return output.unsqueeze(0), hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size)).double()\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size):\n",
    "        super(MetaLearner,self).__init__()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 criterion,\n",
    "                 learning_rate,\n",
    "                 embeddings=one_hot_embeddings):\n",
    "        \n",
    "        super(Learner,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = EncoderLSTM(input_size, hidden_size)\n",
    "        self.decoder = DecoderLSTM(input_size, hidden_size, output_size)\n",
    "        self.encoder_optimizer = torch.optim.Adam(self.encoder.parameters(), lr=learning_rate)\n",
    "        self.decoder_optimizer = torch.optim.Adam(self.decoder.parameters(), lr=learning_rate)\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    \n",
    "    def forward(self, sequence, hidden):\n",
    "        \n",
    "        output = []\n",
    "        sequence_length = sequence.size()[1]\n",
    "        loss = 0\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(hidden)\n",
    "        encoder_hidden = (encoder_hidden, encoder_hidden) # Need a tuple\n",
    "\n",
    "        # Encoder is fed the flipped control sequence\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input  \n",
    "        \n",
    "        # feed encoder_hidden\n",
    "        decoder_input = sequence[0][1] # One after SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        predicted_note_index = 0\n",
    "\n",
    "        for index_control in range(2, sequence_length):\n",
    "            decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            predicted_control_index = int(topi)\n",
    "            \n",
    "            output.append(predicted_control_index)\n",
    "\n",
    "            if random.random() <= 0.9:\n",
    "                decoder_input = sequence[0][index_control].view(1, 1, vocabulary_size)\n",
    "            else:\n",
    "                # This is the next input, without teacher forcing it's the predicted output\n",
    "                decoder_input = torch.from_numpy(self.embeddings[predicted_control_index])\n",
    "                decoder_input = Variable(decoder_input)\n",
    "                if use_cuda:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "                    \n",
    "            # CrossEntropyLoss takes input1: (N, C) and input2: (N).\n",
    "            _, actual_control_index = sequence[0][index_control].topk(1)\n",
    "            if use_cuda:\n",
    "                actual_control_index = actual_control_index.cuda()\n",
    "            loss += self.criterion(decoder_output, actual_control_index)\n",
    "            \n",
    "        return output, loss\n",
    "    \n",
    "    def train(self, sequence, hidden):\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        output, loss = self.forward(sequence, hidden)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "encoder1 = EncoderLSTM(5,5)\n",
    "encoder2 = EncoderLSTM(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.2610  0.4331  0.2729 -0.1771  0.0005\n",
       " 0.0057  0.1114 -0.1566  0.0569  0.3910\n",
       "-0.2347 -0.2272  0.3031 -0.3302  0.2815\n",
       "-0.3309  0.1743 -0.3510 -0.0948  0.0784\n",
       " 0.2381 -0.2602 -0.4434 -0.3815  0.0747\n",
       "-0.0825  0.2122 -0.3795 -0.4332 -0.3532\n",
       " 0.1605 -0.3901  0.2161  0.2075 -0.0334\n",
       "-0.0916  0.3068  0.2008 -0.2449  0.3019\n",
       " 0.4311 -0.0324  0.1797 -0.2204 -0.3622\n",
       " 0.1890  0.2445 -0.2052 -0.0807  0.1944\n",
       "-0.4039  0.2079 -0.3889  0.0714 -0.3463\n",
       "-0.0469  0.4437 -0.2979 -0.0398 -0.2388\n",
       "-0.0332 -0.1388  0.3420 -0.3059 -0.2158\n",
       " 0.4398  0.2785  0.4244 -0.4295 -0.3180\n",
       "-0.3789 -0.1014 -0.2710  0.3379 -0.1847\n",
       " 0.2796  0.0084  0.4023  0.3928  0.2777\n",
       " 0.2643 -0.3386 -0.4349  0.2461  0.2022\n",
       " 0.4121  0.0849  0.3388  0.4083  0.3810\n",
       "-0.3487  0.0788 -0.4308 -0.0355 -0.0311\n",
       " 0.4008  0.1055 -0.3978  0.0637  0.2238\n",
       "[torch.DoubleTensor of size 20x5]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1.lstm.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-0.2651  0.1933  0.4374  0.3999  0.3224\n",
       "-0.1832  0.4113  0.3490  0.1361 -0.2020\n",
       " 0.1873  0.3269 -0.0275  0.3359  0.1357\n",
       "-0.3396  0.1453  0.2452  0.2933 -0.3389\n",
       "-0.0287  0.3502  0.2520  0.0321 -0.3406\n",
       " 0.3427  0.1971 -0.3090  0.4287 -0.0327\n",
       "-0.2465 -0.1550  0.2877  0.1485 -0.1522\n",
       " 0.1656 -0.1220 -0.4063  0.2780 -0.0665\n",
       " 0.0831 -0.3152  0.3622 -0.0480  0.3943\n",
       " 0.4343  0.2587 -0.3178  0.2025 -0.3326\n",
       "-0.3127  0.3550  0.3487  0.1612  0.0728\n",
       " 0.0390  0.2703 -0.3676 -0.1714  0.3557\n",
       "-0.3950  0.2204  0.0851  0.2939 -0.2697\n",
       " 0.0419 -0.4395  0.4177  0.1232 -0.1082\n",
       "-0.3512 -0.0014 -0.0535  0.3175  0.2017\n",
       " 0.4034  0.0054  0.1865 -0.2414 -0.3439\n",
       " 0.1934 -0.1225  0.3401 -0.1114  0.3615\n",
       " 0.3848  0.1728 -0.4038 -0.2881  0.1532\n",
       "-0.0879  0.4038  0.1651  0.1497  0.0924\n",
       " 0.0973 -0.4003  0.3037  0.3747  0.2102\n",
       "[torch.DoubleTensor of size 20x5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder2.lstm.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-0.2651  0.1933  0.4374  0.3999  0.3224\n",
       "-0.1832  0.4113  0.3490  0.1361 -0.2020\n",
       " 0.1873  0.3269 -0.0275  0.3359  0.1357\n",
       "-0.3396  0.1453  0.2452  0.2933 -0.3389\n",
       "-0.0287  0.3502  0.2520  0.0321 -0.3406\n",
       " 0.3427  0.1971 -0.3090  0.4287 -0.0327\n",
       "-0.2465 -0.1550  0.2877  0.1485 -0.1522\n",
       " 0.1656 -0.1220 -0.4063  0.2780 -0.0665\n",
       " 0.0831 -0.3152  0.3622 -0.0480  0.3943\n",
       " 0.4343  0.2587 -0.3178  0.2025 -0.3326\n",
       "-0.3127  0.3550  0.3487  0.1612  0.0728\n",
       " 0.0390  0.2703 -0.3676 -0.1714  0.3557\n",
       "-0.3950  0.2204  0.0851  0.2939 -0.2697\n",
       " 0.0419 -0.4395  0.4177  0.1232 -0.1082\n",
       "-0.3512 -0.0014 -0.0535  0.3175  0.2017\n",
       " 0.4034  0.0054  0.1865 -0.2414 -0.3439\n",
       " 0.1934 -0.1225  0.3401 -0.1114  0.3615\n",
       " 0.3848  0.1728 -0.4038 -0.2881  0.1532\n",
       "-0.0879  0.4038  0.1651  0.1497  0.0924\n",
       " 0.0973 -0.4003  0.3037  0.3747  0.2102\n",
       "[torch.DoubleTensor of size 20x5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1.load_state_dict(encoder2.state_dict())\n",
    "encoder1.lstm.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EncoderLSTM' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4c5864f02007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 366\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EncoderLSTM' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for module in encoder.modules():\n",
    "     print(module.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that we need in the learner module\n",
    "+ The init function should take as argument a network class and then create two networks, the theta network and theta' network and define the optimizer\n",
    "+ A function to copy parameters from the theta function to the theta' function\n",
    "+ A forward function that updates the theta' paramters mutiple times based on the examples from the support set and use loss from the meta test set to update the theta paramets\n",
    "+ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
