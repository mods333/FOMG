{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pickle\n",
    "from loaders import *\n",
    "from episode import *\n",
    "from dataset import *\n",
    "\n",
    "from common import *\n",
    "from model import Model\n",
    "from meta_learner import MetaLearner\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data.sampler as sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Some global variables \"\"\"\n",
    "_loader = Loader(502) # 500 + SOS + EOS\n",
    "loader = MIDILoader(_loader)\n",
    "\n",
    "use_cuda = True\n",
    "# Is the tokenizer 1 indexed?\n",
    "vocabulary_size = 16*128*2 + 32*16 + 100 + 1 # 4708 + 1\n",
    "vocabulary_size = vocabulary_size + 2 # SOS (index 4709) and EOS (index 4710)\n",
    "SOS_TOKEN = 4709\n",
    "EOS_TOKEN = 4710\n",
    "\n",
    "encoding_size = 500\n",
    "one_hot_embeddings = np.eye(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "meta_learner = MetaLearner(Model, (vocabulary_size,encoding_size,vocabulary_size,lr), lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eurythmics wouldilietoyou.mid\n",
      "Eurythmics dontaskmewhy.mid\n",
      "Eurythmics walkingonbrokenglasses.mid\n",
      "Eurythmics nomoreiloveyou.mid\n",
      "Eurythmics sweetdreams.mid\n",
      "Eurythmics thorninmyside.mid\n",
      "Eurythmics lovesongforavampire.mid\n",
      "Eurythmics lilywashere.mid\n",
      "Eurythmics theremustbeanangel.mid\n",
      "Eurythmics dontletitbringyoudown.mid\n",
      "Eurythmics ionlywanttobewithyou.mid\n",
      "Eurythmics themiracleoflove.mid\n",
      "Eurythmics loveisastranger.mid\n",
      "Eurythmics itsalright.mid\n",
      "Eurythmics isavedtheworldtoday.mid\n",
      "ZZ Top nastydogs&funkykings.mid\n",
      "ZZ Top jesusjustleftchicago.mid\n",
      "ZZ Top ithankyou.mid\n",
      "ZZ Top stages.mid\n",
      "ZZ Top roughboys.mid\n",
      "ZZ Top sleepingbag.mid\n",
      "ZZ Top afoolforyourstockings.mid\n",
      "ZZ Top waitingonthebus.mid\n",
      "ZZ Top doubleback.mid\n",
      "ZZ Top pincushion.mid\n",
      "ZZ Top jailhouserock.mid\n",
      "ZZ Top imbadimnationwide.mid\n",
      "ZZ Top gotmeunderpressure.mid\n",
      "ZZ Top sharp-dressedman.mid\n",
      "ZZ Top legrange.mid\n",
      "Slipknot eyeless.mid\n",
      "Slipknot theblisterexists.mid\n",
      "Slipknot getthis.mid\n",
      "Slipknot enjoythesilence.mid\n",
      "Slipknot meinside.mid\n",
      "Slipknot skinticket.mid\n",
      "Slipknot thenameless.mid\n",
      "Slipknot theshape.mid\n",
      "Slipknot diluted.mid\n",
      "Slipknot dangerkeepaway.mid\n",
      "Slipknot scream.mid\n",
      "Slipknot metabolic.mid\n",
      "Slipknot dontgetclose.mid\n",
      "Slipknot waitandbleed.mid\n",
      "Slipknot vermilion.mid\n"
     ]
    }
   ],
   "source": [
    "eps = load_sampler_from_config(\"../src/config.yaml\")\n",
    "episode = eps.get_episode()\n",
    "train = episode.support\n",
    "test = episode.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.2058376205908825, 5.560542528638131, 5.575891550246321]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6a0f6f9301c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The expected input is a batch of control sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FOMG/src/meta_learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, support_x, query_x)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# for each task/episode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_batchsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FOMG/src/meta_learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, support_x, query_x, num_updates)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Find the loss on the query set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         grads_pi = autograd.grad(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FOMG/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_seqs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;31m#print(\"decoder_input: %d\" % (np.where(decoder_input.data==1)[2][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train is a list of list\n",
    "# For each artist there are k number of songs\n",
    "# The expected input is a batch of control sequences\n",
    "for i in range(10):\n",
    "    accs = meta_learner(train, test)\n",
    "    print(accs)\n",
    "\n",
    "#print(meta_learner.learner.meta_net.map_inference(input_variables[0][0:100].view(100, 1, vocabulary_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = train[0][0]\n",
    "song = song.tolist()\n",
    "midi = loader.detokenize(np.array(song))\n",
    "midi.write('orig.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = loader.detokenize(np.array(song[:30]))\n",
    "midi.write('song.mid')\n",
    "\n",
    "gen_seq = meta_learner.learner.learner_net.map_inference(np.array([song[:30]]))\n",
    "midi = loader.detokenize(np.array(song[:30] + gen_seq[0]))\n",
    "midi.write('pred.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(meta_learner.state_dict(), \"../models/song.mod\")\n",
    "\n",
    "pickle.dump(episode, open(\"../models/episode\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.load_state_dict(torch.load('../models/maml_e-2_3000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = pickle.load(open(\"../models/episode\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = eps.support\n",
    "test = eps.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = load_sampler_from_config(\"../src/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Buckley whatwillyousay.mid\n",
      "Jeff Buckley corpuschristicarol.mid\n",
      "Jeff Buckley demonjohn.mid\n",
      "Jeff Buckley grace.mid\n",
      "Jeff Buckley jenenconnaispaslafin(live).mid\n",
      "Jeff Buckley haventyouheard.mid\n",
      "Jeff Buckley lastgoodbye.mid\n",
      "Jeff Buckley soreal.mid\n",
      "Jeff Buckley witchesrave.mid\n",
      "Jeff Buckley openedonce.mid\n",
      "Jeff Buckley satisfiedmind.mid\n",
      "Jeff Buckley nightmaresbythesea.mid\n",
      "Jeff Buckley dreambrother.mid\n",
      "Jeff Buckley eternallife.mid\n",
      "Jeff Buckley hallelujah.mid\n",
      "Santana oyemicanto.mid\n",
      "Santana everybodyseverything.mid\n",
      "Santana songofthewind.mid\n",
      "Santana whydontyouandi.mid\n",
      "Santana imgonejam.mid\n",
      "Santana jingo.mid\n",
      "Santana blackmagicwoman.mid\n",
      "Santana smooth.mid\n",
      "Santana sambapati.mid\n",
      "Santana loveofmylife.mid\n",
      "Santana corazónespinado.mid\n",
      "Santana europa.mid\n",
      "Santana mariamaria.mid\n",
      "Santana shesnotthere.mid\n",
      "Santana merengation.mid\n",
      "Christina Aguilera whatagirlwants.mid\n",
      "Christina Aguilera ladymarmaladefeat.mya&pink&lilkim.mid\n",
      "Christina Aguilera genieinabottle.mid\n",
      "Christina Aguilera comeonoverbaby.mid\n",
      "Christina Aguilera iturntoyou.mid\n",
      "Christina Aguilera cantholdusdown.mid\n",
      "Christina Aguilera hurt.mid\n",
      "Christina Aguilera fighter.mid\n",
      "Christina Aguilera voicewithin.mid\n",
      "Christina Aguilera soar.mid\n",
      "Christina Aguilera nobodywantstobelonely.mid\n",
      "Christina Aguilera impossible.mid\n",
      "Christina Aguilera beautiful.mid\n",
      "Christina Aguilera getminegetyours.mid\n",
      "Christina Aguilera ohmother.mid\n"
     ]
    }
   ],
   "source": [
    "ep = eps.get_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ep, open(\"ep\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = pickle.load(open(\"ep\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = ep.support[1]\n",
    "query = ep.query[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4708, 4708, 4708, ...,  186, 4616, 2238],\n",
       "       [4708, 4708, 4708, ..., 4616, 2509, 4611],\n",
       "       [4708, 4708, 4661, ..., 4612, 2624, 4610],\n",
       "       ...,\n",
       "       [4708, 4708, 4708, ..., 2233, 3141, 4376],\n",
       "       [4708, 4708, 4708, ..., 4637, 2624, 4613],\n",
       "       [4708, 4708, 4708, ..., 4610,  572, 4634]], dtype=int32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "meta_learner = MetaLearner(Model, (vocabulary_size,encoding_size,vocabulary_size,lr), lr, 1)\n",
    "meta_learner.load_state_dict(torch.load('../models/maml_e-3_3000'))\n",
    "\n",
    "learner = meta_learner.learner.meta_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 0m 35s) (1 5%) 3.1161\n",
      "0m 4s (- 0m 38s) (2 10%) 2.7053\n",
      "0m 6s (- 0m 37s) (3 15%) 2.8596\n",
      "0m 8s (- 0m 35s) (4 20%) 3.0919\n",
      "0m 11s (- 0m 34s) (5 25%) 2.5456\n",
      "0m 13s (- 0m 32s) (6 30%) 2.0584\n",
      "0m 16s (- 0m 29s) (7 35%) 1.7812\n",
      "0m 18s (- 0m 27s) (8 40%) 1.5116\n",
      "0m 20s (- 0m 25s) (9 45%) 1.3091\n",
      "0m 23s (- 0m 23s) (10 50%) 1.1245\n",
      "0m 25s (- 0m 20s) (11 55%) 0.9653\n",
      "0m 27s (- 0m 18s) (12 60%) 0.8407\n",
      "0m 30s (- 0m 16s) (13 65%) 0.7078\n",
      "0m 32s (- 0m 13s) (14 70%) 0.5735\n",
      "0m 34s (- 0m 11s) (15 75%) 0.4660\n",
      "0m 37s (- 0m 9s) (16 80%) 0.3686\n",
      "0m 39s (- 0m 7s) (17 85%) 0.2901\n",
      "0m 41s (- 0m 4s) (18 90%) 0.2239\n",
      "0m 43s (- 0m 2s) (19 95%) 0.1693\n",
      "0m 45s (- 0m 0s) (20 100%) 0.1282\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train on same song 5 times \"\"\"\n",
    "SEQ_LENGTH = 150 # SOS and EOS\n",
    "SONG_INDEX = 0\n",
    "optimizer = torch.optim.Adam(learner.parameters(), lr)\n",
    "\n",
    "learner.train()\n",
    "\n",
    "print_every = 1\n",
    "total_epochs = 20\n",
    "print_loss_total = 0\n",
    "startTime = time.time()\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    \n",
    "    loss = learner(support)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print_loss_total += (loss/SEQ_LENGTH)\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(startTime, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/model.py:223: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = softmax(decoder_output).data.cpu()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2980, 4611, 2712, 4271, 664, 4613, 1091, 4610, 2499, 4610, 4220, 461, 4222, 2509, 4640, 4204, 448, 4629, 460, 4631, 2516, 4276, 470, 4614, 2509, 4631, 2518, 4610, 461, 470, 4660, 2494, 4214, 468, 4615, 668, 4613, 448, 465, 4660, 2518, 4610, 4210, 470, 4212, 446, 4631, 2518, 4277, 4214, 461, 4280, 678, 4480, 1434, 4631, 2516, 4610, 4214, 2516, 4212, 448, 4631, 448, 4612, 4472, 1429, 4629, 2513, 4210, 470, 4633, 2494, 468, 4214, 470, 4639, 446, 4631, 2516, 4610, 470, 4631, 446, 468, 4610, 2513, 4210, 448, 4631, 2518, 4610, 465, 470, 4660, 2494, 4214, 448, 4629, 2494, 467, 4610, 2513, 4210, 448, 4633, 2515, 2496, 470, 4611, 4629, 2494, 2518, 2518, 4210, 446, 4212, 446, 4631, 2516, 4710, 470, 4612, 2494, 2518, 4612, 2496, 3477, 4212, 448, 4631, 2518, 4211, 465, 4629, 2518, 4610, 2496, 4612, 4210, 461, 4212, 448, 4631, 1434, 4710, 470, 1429, 4629, 2496, 4610, 2496, 470, 4212, 446, 4212, 448, 4631, 2513, 2516, 4612, 1429, 3477, 4211, 446, 4612, 2513, 4629, 448, 4610, 2496, 470, 446, 446, 4660, 2494, 4211, 448, 4631, 2515, 2516, 4610, 2513, 4210, 468, 4633, 2515, 467, 4629, 1429, 4609, 2516, 4610, 470, 4631, 446, 470, 4660, 2518, 4631, 2516, 4211, 470, 4212, 446, 4631, 4211, 468, 4612, 2515, 4212, 468, 4610, 2513, 4610, 448, 4633, 2494, 4212, 470, 446, 4278, 678, 4631, 2518, 2496, 465, 3477, 4214, 448, 4633, 2515, 4211, 465, 4629, 2518, 4610, 2496, 470, 4214, 468, 4212, 446, 4631, 2516, 4610, 4209, 470, 4629, 2516]\n",
      "[4708 4708 4708 4668 4244  579 4640 2627 4616  584 4640 2632 4616  586\n",
      " 4640 2634 4616  587 4640 2635 4616  586 4640 2634 4636  584 4624 2632\n",
      " 4612  582]\n",
      "[4708 4708 4708 4668 4244  579 4640 2627 4616  584 4640 2632 4616  586\n",
      " 4640 2634 4616  587 4640 2635 4616  586 4640 2634 4636  584 4624 2632\n",
      " 4612  582 2980 4611 2712 4271  664 4613 1091 4610 2499 4610 4220  461\n",
      " 4222 2509 4640 4204  448 4629  460 4631 2516 4276  470 4614 2509 4631\n",
      " 2518 4610  461  470 4660 2494 4214  468 4615  668 4613  448  465 4660\n",
      " 2518 4610 4210  470 4212  446 4631 2518 4277 4214  461 4280  678 4480\n",
      " 1434 4631 2516 4610 4214 2516 4212  448 4631  448 4612 4472 1429 4629\n",
      " 2513 4210  470 4633 2494  468 4214  470 4639  446 4631 2516 4610  470\n",
      " 4631  446  468 4610 2513 4210  448 4631 2518 4610  465  470 4660 2494\n",
      " 4214  448 4629 2494  467 4610 2513 4210  448 4633 2515 2496  470 4611\n",
      " 4629 2494 2518 2518 4210  446 4212  446 4631 2516 4710  470 4612 2494\n",
      " 2518 4612 2496 3477 4212  448 4631 2518 4211  465 4629 2518 4610 2496\n",
      " 4612 4210  461 4212  448 4631 1434 4710  470 1429 4629 2496 4610 2496\n",
      "  470 4212  446 4212  448 4631 2513 2516 4612 1429 3477 4211  446 4612\n",
      " 2513 4629  448 4610 2496  470  446  446 4660 2494 4211  448 4631 2515\n",
      " 2516 4610 2513 4210  468 4633 2515  467 4629 1429 4609 2516 4610  470\n",
      " 4631  446  470 4660 2518 4631 2516 4211  470 4212  446 4631 4211  468\n",
      " 4612 2515 4212  468 4610 2513 4610  448 4633 2494 4212  470  446 4278\n",
      "  678 4631 2518 2496  465 3477 4214  448 4633 2515 4211  465 4629 2518\n",
      " 4610 2496  470 4214  468 4212  446 4631 2516 4610 4209  470 4629 2516]\n"
     ]
    }
   ],
   "source": [
    "learner.eval()\n",
    "song = query[1]\n",
    "midi = loader.detokenize(np.array(song))\n",
    "midi.write('orig.mid')\n",
    "\n",
    "midi = loader.detokenize(np.array(song[:30]))\n",
    "midi.write('song.mid')\n",
    "\n",
    "gen_seq = learner.sample_inference(np.array([song[:30]]))\n",
    "midi = loader.detokenize(np.append(song[:30], np.array(gen_seq[0])))\n",
    "midi.write('pred.mid')\n",
    "print(gen_seq[0])\n",
    "print(song[:30])\n",
    "print(np.append(song[:30], np.array(gen_seq[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
