{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from episode import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "vocabulary_size = 16*128*2 + 32*16 + 100 + 1  # 4708 + 1\n",
    "vocabulary_size = vocabulary_size + 2  # SOS (index 4709) and EOS (index 4710)\n",
    "SOS_TOKEN = 4709\n",
    "EOS_TOKEN = 4710\n",
    "\n",
    "encoding_size = 500\n",
    "one_hot_embeddings = np.eye(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner and MetaLearner Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "\n",
    "    def __init__(self, network_class, *args):\n",
    "\n",
    "        super(Learner, self).__init__()\n",
    "        # define the network for the learner and the meta-learner network\n",
    "        self.meta_net = network_class(*args)\n",
    "        self.learner_net = network_class(*args)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.learner_net.parameters(), 0.01)\n",
    "\n",
    "    def copy_theta(self):\n",
    "\n",
    "        # Ablation test -- set to 0s\n",
    "        self.learner_net.load_state_dict(copy.deepcopy(self.meta_net.state_dict()))\n",
    "\n",
    "    def forward(self, support_x, query_x, num_updates, support_cat, query_cat):\n",
    "\n",
    "        # Copy theta into theta'\n",
    "        self.copy_theta()\n",
    "\n",
    "        # update for several steps\n",
    "        for i in range(num_updates):\n",
    "            # forward and backward to update net_pi grad.\n",
    "            loss = self.learner_net(support_x, support_cat)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Find the loss on the query set\n",
    "        loss = self.learner_net(query_x, query_cat)\n",
    "\n",
    "        grads_pi = autograd.grad(\n",
    "            loss, self.learner_net.parameters(), retain_graph=True)\n",
    "\n",
    "        return loss, grads_pi, loss.data[0]\n",
    "\n",
    "    def net_forward(self, support_x, numbered_seq):\n",
    "\n",
    "        loss = self.meta_net(support_x, numbered_seq)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, network_class, network_args, k_shot, beta, num_updates):\n",
    "\n",
    "        super(MetaLearner, self).__init__()\n",
    "\n",
    "        self.k_shot = k_shot\n",
    "        self.beta = beta\n",
    "        self.num_updates = num_updates\n",
    "\n",
    "        # it will contains a learner class to learn on episodes and gather the loss together.\n",
    "        self.learner = Learner(network_class, *network_args)\n",
    "        # the optimizer is to update theta parameters, not theta_pi parameters.\n",
    "        self.optimizer = torch.optim.Adam(self.learner.meta_net.parameters(), lr=beta)\n",
    "\n",
    "    def write_grads(self, dummy_loss, sum_grads_pi):\n",
    "        \"\"\"\n",
    "        write loss into learner.net, gradients come from sum_grads_pi.\n",
    "        Since the gradients info is not calculated by general backward, we need this function to write the right gradients\n",
    "        into theta network and update theta parameters as wished.\n",
    "        :param dummy_loss: dummy loss, nothing but to write our gradients by hook\n",
    "        :param sum_grads_pi: the summed gradients\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Register a hook on each parameter in the net that replaces the current dummy grad\n",
    "        # with our grads accumulated across the meta-batch\n",
    "        hooks = []\n",
    "\n",
    "        for i, v in enumerate(self.learner.parameters()):\n",
    "            def closure():\n",
    "                ii = i\n",
    "                return lambda grad: sum_grads_pi[ii]\n",
    "\n",
    "            # if you write: hooks.append( v.register_hook(lambda grad : sum_grads_pi[i]) )\n",
    "            # it will pop an ERROR, i don't know why?\n",
    "            hooks.append(v.register_hook(closure()))\n",
    "\n",
    "        # use our sumed gradients_pi to update the theta/net network,\n",
    "        # since our optimizer receive the self.net.parameters() only.\n",
    "        self.optimizer.zero_grad()\n",
    "        dummy_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # if you do NOT remove the hook, the GPU memory will expode!!!\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "    def forward(self, support_x, query_x, support_cat, query_cat):\n",
    "\n",
    "        sum_grads_pi = None\n",
    "        # (T_i, seq_length, batch_size, vocab_size)\n",
    "        meta_batchsz = support_x.size(0)\n",
    "\n",
    "        # we do different learning task sequentially, not parallel.\n",
    "        accs = []\n",
    "        # for each task/episode.\n",
    "        for i in range(meta_batchsz):\n",
    "            # ASSUME QUERY SET IS ALWAYS SIZE 1\n",
    "            _, grad_pi, episode_acc = self.learner(\n",
    "                support_x[i], query_x[0], self.num_updates, support_cat[i], query_cat[0])\n",
    "            accs.append(episode_acc)\n",
    "            if sum_grads_pi is None:\n",
    "                sum_grads_pi = grad_pi\n",
    "            else:  # accumulate all gradients from different episode learner\n",
    "                sum_grads_pi = [torch.add(i, j)\n",
    "                                for i, j in zip(sum_grads_pi, grad_pi)]\n",
    "\n",
    "        # As we already have the grads to update\n",
    "        # We use a dummy forward / backward pass to get the correct grads into self.net\n",
    "        # the right grads will be updated by hook, ignoring backward.\n",
    "        # use hook mechnism to write sumed gradient into network.\n",
    "        # we need to update the theta/net network, we need a op from net network, so we call self.learner.net_forward\n",
    "        # to get the op from net network, since the loss from self.learner.forward will return loss from net_pi network.\n",
    "        dummy_loss = self.learner.net_forward(support_x[0], support_cat[0])\n",
    "        self.write_grads(dummy_loss, sum_grads_pi)\n",
    "\n",
    "        return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "Just a simple LSTM encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "\n",
    "    def forward(self, input, hidden_in):\n",
    "        # encoder only outputs hidden\n",
    "        _, hidden_out = self.lstm(input, hidden_in)\n",
    "        return hidden_out\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "\n",
    "        result = Variable(torch.zeros(\n",
    "            1, batch_size, self.hidden_size)).double()\n",
    "\n",
    "        if use_cuda:\n",
    "            result = result.cuda()\n",
    "        return result\n",
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double()\n",
    "        self.out = nn.Linear(hidden_size, output_size).double()\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.out = self.out.cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # output = F.relu(input) \n",
    "        # FIXME: Don't think we need the RELU?  Input is one-hot, RELU does nothing. \n",
    "        output, hidden = self.lstm(input, hidden)\n",
    "        output = self.out(output)\n",
    "        output = output.squeeze()\n",
    "        return output.unsqueeze(0), hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            1, batch_size, self.hidden_size)).double()\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def compute_loss(logits, target, length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = F.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = _sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.double()\n",
    "    loss = losses.sum() / length.double().sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size, encoding_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = EncoderLSTM(vocabulary_size, encoding_size)\n",
    "        self.decoder = DecoderLSTM(\n",
    "            vocabulary_size, encoding_size, vocabulary_size)\n",
    "        self.teacher_forcing = 0.9\n",
    "\n",
    "    def forward(self, sequence, numbered_seq):\n",
    "\n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        seq_size = sequence.size()\n",
    "        batch_size = seq_size[1]\n",
    "        sequence_length = seq_size[0]\n",
    "        loss = 0\n",
    "\n",
    "        encoder_hidden = (encoder.initHidden(batch_size),\n",
    "                          encoder.initHidden(batch_size))\n",
    "\n",
    "        # Encoder is fed the flipped control sequence\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[index_control].unsqueeze(\n",
    "                0)  # (1, batch_size, vocab_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # feed encoder_hidden\n",
    "        decoder_input = sequence[0].unsqueeze(0)  # This is SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Prepare the results tensor\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        all_decoder_outputs = Variable(torch.zeros(*sequence.size())).double()\n",
    "        if use_cuda:\n",
    "            all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "        all_decoder_outputs[0] = decoder_input\n",
    "\n",
    "        for index_control in range(1, sequence_length):\n",
    "            # decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "\n",
    "            if random.random() <= self.teacher_forcing:\n",
    "                decoder_input = sequence[index_control].unsqueeze(0)\n",
    "            else:\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                # This is the next input, without teacher forcing it's the predicted output\n",
    "                decoder_input = torch.stack([Variable(torch.DoubleTensor(one_hot_embeddings[ni]))\n",
    "                                             for ni in topi.squeeze()]).unsqueeze(0)\n",
    "                if use_cuda:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Save the decoder output\n",
    "            all_decoder_outputs[index_control] = decoder_output\n",
    "\n",
    "        seq_lens = Variable(torch.LongTensor(\n",
    "            np.ones(batch_size, dtype=int)*sequence_length))\n",
    "        if use_cuda:\n",
    "            seq_lens = seq_lens.cuda()\n",
    "\n",
    "        loss = compute_loss(all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "                            numbered_seq.transpose(0, 1).contiguous(),\n",
    "                            seq_lens)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def map_inference(self, sequence, embeddings=one_hot_embeddings, max_length=250):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            sequence: (seq_length, batch, vocab_size)\n",
    "            output: [[seq1], ..., [seqN]] where N is number of batch\n",
    "        \"\"\"\n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        seq_size = sequence.size()\n",
    "        batch_size = seq_size[1]\n",
    "        sequence_length = seq_size[0]\n",
    "\n",
    "        encoder_hidden = (encoder.initHidden(batch_size),\n",
    "                          encoder.initHidden(batch_size))\n",
    "\n",
    "        # Encoder is fed the flipped control sequence\n",
    "        for index_control in np.arange(sequence_length-1, 0, -1):\n",
    "            encoder_input = sequence[index_control].unsqueeze(\n",
    "                0)  # (1, batch_size, vocab_size)\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # feed encoder_hidden\n",
    "        decoder_input = sequence[0].unsqueeze(0)  # This is SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        output_control_sequences = [[] for batch in range(batch_size)]\n",
    "        append_flag = [True for batch in range(batch_size)]\n",
    "        # Prepare the results tensor\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        index_control = 1\n",
    "        while True:\n",
    "            # decoder_input = decoder_input.view(1, 1, vocabulary_size)\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "            next_input = []\n",
    "            for index, ni in enumerate(topi.squeeze()):\n",
    "                next_input.append(\n",
    "                    Variable(torch.DoubleTensor(one_hot_embeddings[ni])))\n",
    "                # If we hit an EOS, stop appending to that output sequence\n",
    "                if ni == EOS_TOKEN:\n",
    "                    append_flag[index] = False\n",
    "                if append_flag[index]:\n",
    "                    output_control_sequences[index].append(ni)\n",
    "\n",
    "            decoder_input = torch.stack(next_input).unsqueeze(0)\n",
    "\n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            index_control += 1\n",
    "            if index_control >= max_length:\n",
    "                break\n",
    "\n",
    "        return output_control_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = '../data/small/'\n",
    "training_set = np.load(base_path + 'beethoven_brunomars_eminem_mozart.npy')\n",
    "train_size = len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" RUN THIS ONLY MANUALLY! \"\"\"\n",
    "meta_learner = MetaLearner(Model, (vocabulary_size, encoding_size), 1, 0.02, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Convert to one-hot \"\"\"\n",
    "SEQ_LENGTH = 250\n",
    "training_one_hot = []\n",
    "training_categories = []\n",
    "for i in range(train_size):\n",
    "    training_categories.append(np.concatenate(([SOS_TOKEN], training_set[i][0:SEQ_LENGTH], [EOS_TOKEN])))\n",
    "    training_one_hot.append(one_hot_embeddings[training_categories[i]])\n",
    "    \n",
    "training_one_hot = np.array(training_one_hot)\n",
    "training_categories = np.array(training_categories, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 252, 4711)\n",
      "(101, 252)\n"
     ]
    }
   ],
   "source": [
    "print(training_one_hot.shape)\n",
    "print(training_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" CAUTION: RUN THIS ONLY MANUALLY! \"\"\"\n",
    "meta_learner.load_state_dict(torch.load(\"../models/maml_combined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20m 14s (- 465m 32s) (1 4%) 505.4966\n",
      "40m 32s (- 445m 55s) (2 8%) 521.8807\n",
      "60m 50s (- 425m 54s) (3 12%) 486.5450\n",
      "81m 8s (- 405m 44s) (4 16%) 478.9368\n",
      "101m 27s (- 385m 31s) (5 20%) 467.0125\n",
      "121m 45s (- 365m 15s) (6 25%) 537.2839\n",
      "142m 3s (- 344m 59s) (7 29%) 457.8210\n",
      "162m 21s (- 324m 42s) (8 33%) 448.3797\n",
      "182m 40s (- 304m 27s) (9 37%) 481.5830\n",
      "203m 0s (- 284m 12s) (10 41%) 475.0951\n",
      "223m 18s (- 263m 54s) (11 45%) 485.0946\n",
      "243m 35s (- 243m 35s) (12 50%) 477.2808\n",
      "263m 53s (- 223m 17s) (13 54%) 460.3866\n",
      "284m 13s (- 203m 0s) (14 58%) 477.5971\n",
      "304m 33s (- 182m 43s) (15 62%) 465.0226\n",
      "324m 51s (- 162m 25s) (16 66%) 417.0749\n",
      "345m 10s (- 142m 7s) (17 70%) 447.4723\n",
      "365m 28s (- 121m 49s) (18 75%) 485.9039\n",
      "385m 46s (- 101m 31s) (19 79%) 461.2885\n",
      "406m 10s (- 81m 14s) (20 83%) 451.2395\n",
      "426m 28s (- 60m 55s) (21 87%) 452.3545\n",
      "446m 46s (- 40m 36s) (22 91%) 460.0591\n",
      "467m 4s (- 20m 18s) (23 95%) 469.0420\n",
      "487m 21s (- 0m 0s) (24 100%) 459.0662\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 24\n",
    "TASK_BATCH_SIZE = 4 + 1 # 3 support + 1 query\n",
    "SEQ_LENGTH = 252 # SOS and EOS\n",
    "\n",
    "print_every = 1\n",
    "check_every = 1\n",
    "print_loss_total = 0\n",
    "startTime = time.time()\n",
    "randomize_song_index = np.arange(train_size)\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    # Randomize\n",
    "    np.random.shuffle(randomize_song_index)\n",
    "    training_one_hot = training_one_hot[randomize_song_index]\n",
    "    training_categories = training_categories[randomize_song_index]\n",
    "    \n",
    "    for task_batch in range(train_size // TASK_BATCH_SIZE):\n",
    "        batch_start = task_batch * TASK_BATCH_SIZE\n",
    "        batch_end = batch_start + TASK_BATCH_SIZE\n",
    "        batch = training_one_hot[batch_start:batch_end]\n",
    "        \n",
    "        support = batch[:-1]\n",
    "        support_cat = training_categories[batch_start:batch_end-1]\n",
    "        query = batch[-1:]\n",
    "        query_cat = training_categories[batch_end-1:batch_end]\n",
    "        \n",
    "        support = Variable(torch.from_numpy(support)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        support_cat = Variable(torch.from_numpy(support_cat)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1)\n",
    "        query = Variable(torch.from_numpy(query)).view(1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        query_cat = Variable(torch.from_numpy(query_cat)).view(1, SEQ_LENGTH, 1)\n",
    "        if use_cuda:\n",
    "            support = support.cuda()\n",
    "            support_cat = support_cat.cuda()\n",
    "            query = query.cuda()\n",
    "            query_cat = query_cat.cuda()\n",
    "        # support_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # query_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # num_seq : (T_i, seq_length, batch_size)\n",
    "        \n",
    "        loss = meta_learner(support, query, support_cat, query_cat)\n",
    "        print_loss_total += np.sum(np.array(loss))\n",
    "        \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(startTime, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg)) \n",
    "        \n",
    "    if epoch % check_every == 0:\n",
    "        # torch.save(meta_learner.state_dict(), '../models/maml_'+str(epoch))\n",
    "        torch.save(meta_learner.state_dict(), '../models/maml_combined')\n",
    "        torch.save(meta_learner.learner.meta_net.state_dict(), '../models/maml_meta_net')\n",
    "        torch.save(meta_learner.learner.learner_net.state_dict(), '../models/maml_learner_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70m 24s (- 1619m 14s) (1 4%) 486.0481\n",
      "140m 48s (- 1548m 53s) (2 8%) 424.5096\n",
      "211m 16s (- 1478m 55s) (3 12%) 424.8192\n",
      "281m 46s (- 1408m 54s) (4 16%) 436.2185\n",
      "352m 14s (- 1338m 32s) (5 20%) 475.5978\n",
      "422m 43s (- 1268m 11s) (6 25%) 400.9369\n",
      "493m 11s (- 1197m 45s) (7 29%) 397.1466\n",
      "563m 38s (- 1127m 16s) (8 33%) 393.3860\n",
      "634m 5s (- 1056m 49s) (9 37%) 373.3076\n",
      "704m 33s (- 986m 22s) (10 41%) 396.3115\n",
      "775m 1s (- 915m 55s) (11 45%) 348.9484\n",
      "845m 30s (- 845m 30s) (12 50%) 338.5595\n",
      "915m 56s (- 775m 1s) (13 54%) 354.5077\n",
      "986m 25s (- 704m 35s) (14 58%) 321.8567\n",
      "1056m 54s (- 634m 8s) (15 62%) 312.3348\n",
      "1127m 23s (- 563m 41s) (16 66%) 305.7680\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 24\n",
    "TASK_BATCH_SIZE = 4 + 1 # 3 support + 1 query\n",
    "SEQ_LENGTH = 252 # SOS and EOS\n",
    "\n",
    "print_every = 1\n",
    "check_every = 1\n",
    "print_loss_total = 0\n",
    "startTime = time.time()\n",
    "randomize_song_index = np.arange(train_size)\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    # Randomize\n",
    "    np.random.shuffle(randomize_song_index)\n",
    "    training_one_hot = training_one_hot[randomize_song_index]\n",
    "    training_categories = training_categories[randomize_song_index]\n",
    "    \n",
    "    for task_batch in range(train_size // TASK_BATCH_SIZE):\n",
    "        batch_start = task_batch * TASK_BATCH_SIZE\n",
    "        batch_end = batch_start + TASK_BATCH_SIZE\n",
    "        batch = training_one_hot[batch_start:batch_end]\n",
    "        \n",
    "        support = batch[:-1]\n",
    "        support_cat = training_categories[batch_start:batch_end-1]\n",
    "        query = batch[-1:]\n",
    "        query_cat = training_categories[batch_end-1:batch_end]\n",
    "        \n",
    "        support = Variable(torch.from_numpy(support)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        support_cat = Variable(torch.from_numpy(support_cat)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1)\n",
    "        query = Variable(torch.from_numpy(query)).view(1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        query_cat = Variable(torch.from_numpy(query_cat)).view(1, SEQ_LENGTH, 1)\n",
    "        if use_cuda:\n",
    "            support = support.cuda()\n",
    "            support_cat = support_cat.cuda()\n",
    "            query = query.cuda()\n",
    "            query_cat = query_cat.cuda()\n",
    "        # support_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # query_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # num_seq : (T_i, seq_length, batch_size)\n",
    "        \n",
    "        loss = meta_learner(support, query, support_cat, query_cat)\n",
    "        print_loss_total += np.sum(np.array(loss))\n",
    "        \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(startTime, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg)) \n",
    "        \n",
    "    if epoch % check_every == 0:\n",
    "        # torch.save(meta_learner.state_dict(), '../models/maml_'+str(epoch))\n",
    "        torch.save(meta_learner.state_dict(), '../models/maml_combined')\n",
    "        torch.save(meta_learner.learner.meta_net.state_dict(), '../models/maml_meta_net')\n",
    "        torch.save(meta_learner.learner.learner_net.state_dict(), '../models/maml_learner_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70m 37s (- 1624m 30s) (1 4%) 431.4280\n",
      "141m 15s (- 1553m 47s) (2 8%) 298.0266\n",
      "211m 51s (- 1482m 58s) (3 12%) 310.1591\n",
      "282m 27s (- 1412m 15s) (4 16%) 293.9344\n",
      "353m 1s (- 1341m 30s) (5 20%) 251.5265\n",
      "423m 38s (- 1270m 54s) (6 25%) 228.3711\n",
      "494m 14s (- 1200m 18s) (7 29%) 257.9870\n",
      "564m 51s (- 1129m 43s) (8 33%) 249.5803\n",
      "635m 29s (- 1059m 8s) (9 37%) 227.3710\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-55510d4ef868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# num_seq : (T_i, seq_length, batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f23b0d1a8a5b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, support_x, query_x, support_cat, query_cat)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# ASSUME QUERY SET IS ALWAYS SIZE 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             _, grad_pi, episode_acc = self.learner(\n\u001b[1;32m---> 61\u001b[1;33m                 support_x[i], query_x[0], self.num_updates, support_cat[i], query_cat[0])\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0maccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msum_grads_pi\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-99503e30231c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, support_x, query_x, num_updates, support_cat, query_cat)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_updates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# forward and backward to update net_pi grad.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7281368b0c77>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sequence, numbered_seq)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         encoder_hidden = (encoder.initHidden(batch_size),\n\u001b[0m\u001b[0;32m     68\u001b[0m                           encoder.initHidden(batch_size))\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8b748f68bde6>\u001b[0m in \u001b[0;36minitHidden\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\_functions\\tensor.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, i, device, async)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_epochs = 24\n",
    "TASK_BATCH_SIZE = 4 + 1 # 3 support + 1 query\n",
    "SEQ_LENGTH = 252 # SOS and EOS\n",
    "\n",
    "print_every = 1\n",
    "check_every = 1\n",
    "print_loss_total = 0\n",
    "startTime = time.time()\n",
    "randomize_song_index = np.arange(train_size)\n",
    "for epoch in range(1, total_epochs+1):\n",
    "    # Randomize\n",
    "    np.random.shuffle(randomize_song_index)\n",
    "    training_one_hot = training_one_hot[randomize_song_index]\n",
    "    training_categories = training_categories[randomize_song_index]\n",
    "    \n",
    "    for task_batch in range(train_size // TASK_BATCH_SIZE):\n",
    "        batch_start = task_batch * TASK_BATCH_SIZE\n",
    "        batch_end = batch_start + TASK_BATCH_SIZE\n",
    "        batch = training_one_hot[batch_start:batch_end]\n",
    "        \n",
    "        support = batch[:-1]\n",
    "        support_cat = training_categories[batch_start:batch_end-1]\n",
    "        query = batch[-1:]\n",
    "        query_cat = training_categories[batch_end-1:batch_end]\n",
    "        \n",
    "        support = Variable(torch.from_numpy(support)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        support_cat = Variable(torch.from_numpy(support_cat)).view(TASK_BATCH_SIZE-1, SEQ_LENGTH, 1)\n",
    "        query = Variable(torch.from_numpy(query)).view(1, SEQ_LENGTH, 1, vocabulary_size)\n",
    "        query_cat = Variable(torch.from_numpy(query_cat)).view(1, SEQ_LENGTH, 1)\n",
    "        if use_cuda:\n",
    "            support = support.cuda()\n",
    "            support_cat = support_cat.cuda()\n",
    "            query = query.cuda()\n",
    "            query_cat = query_cat.cuda()\n",
    "        # support_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # query_x : (T_i, seq_length, batch_size, vocab_size)\n",
    "        # num_seq : (T_i, seq_length, batch_size)\n",
    "        \n",
    "        loss = meta_learner(support, query, support_cat, query_cat)\n",
    "        print_loss_total += np.sum(np.array(loss))\n",
    "        \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(startTime, epoch / total_epochs),\n",
    "                                     epoch, epoch / total_epochs * 100, print_loss_avg)) \n",
    "        \n",
    "    if epoch % check_every == 0:\n",
    "        # torch.save(meta_learner.state_dict(), '../models/maml_'+str(epoch))\n",
    "        torch.save(meta_learner.state_dict(), '../models/maml_combined')\n",
    "        torch.save(meta_learner.learner.meta_net.state_dict(), '../models/maml_meta_net')\n",
    "        torch.save(meta_learner.learner.learner_net.state_dict(), '../models/maml_learner_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" CAUTION: RUN THIS ONLY MANUALLY! \"\"\"\n",
    "meta_learner.load_state_dict(torch.load(\"../models/maml_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = '../data/small/'\n",
    "testing_set = np.load(base_path + 'tchaikovsky.npy')\n",
    "test_size = len(testing_set)\n",
    "\n",
    "\"\"\" Convert to one-hot \"\"\"\n",
    "SEQ_LENGTH = 250\n",
    "testing_one_hot = []\n",
    "testing_categories = []\n",
    "for i in range(test_size):\n",
    "    testing_categories.append(np.concatenate(([SOS_TOKEN], testing_set[i][0:SEQ_LENGTH], [EOS_TOKEN])))\n",
    "    testing_one_hot.append(one_hot_embeddings[testing_categories[i]])\n",
    "    \n",
    "testing_one_hot = np.array(testing_one_hot)\n",
    "testing_categories = np.array(testing_categories, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 252, 4711)\n",
      "(12, 252)\n"
     ]
    }
   ],
   "source": [
    "print(testing_one_hot.shape)\n",
    "print(testing_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "eval_model = Model(vocabulary_size, encoding_size)\n",
    "eval_model.load_state_dict(copy.deepcopy(meta_learner.learner.meta_net.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.426447595368616\n",
      "3.6857630964445613\n",
      "3.058252701077426\n",
      "2.671283233182042\n",
      "2.097475303351734\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train on same song 5 times \"\"\"\n",
    "SEQ_LENGTH = 252 # SOS and EOS\n",
    "SONG_INDEX = 0\n",
    "optimizer = torch.optim.Adam(eval_model.parameters(), 0.01)\n",
    "\n",
    "eval_model.train()\n",
    "for _ in range(5):\n",
    "    sequence = Variable(torch.from_numpy(testing_one_hot[SONG_INDEX])).view(SEQ_LENGTH, 1, vocabulary_size)\n",
    "    category = Variable(torch.from_numpy(testing_categories[SONG_INDEX])).view(SEQ_LENGTH, 1)\n",
    "    if use_cuda:\n",
    "        sequence = sequence.cuda()\n",
    "        category = category.cuda()\n",
    "        \n",
    "    loss = eval_model(sequence, category)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.data[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAP Inference on the same song \"\"\"\n",
    "eval_model.eval()\n",
    "TEST_LENGTH = 100\n",
    "\n",
    "sequence = Variable(torch.from_numpy(testing_one_hot[SONG_INDEX][0:TEST_LENGTH])).view(TEST_LENGTH, 1, vocabulary_size)\n",
    "if use_cuda:\n",
    "    sequence = sequence.cuda()\n",
    "out_sequence = eval_model.map_inference(sequence, max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249,)\n"
     ]
    }
   ],
   "source": [
    "from loaders import *\n",
    "_loader = Loader(500)\n",
    "loader = MIDILoader(_loader)\n",
    "\n",
    "whole_sequence = np.concatenate((testing_categories[SONG_INDEX][0:TEST_LENGTH], np.array(out_sequence[0])))\n",
    "print(whole_sequence.shape)\n",
    "midi_sequence = loader.detokenize(whole_sequence)\n",
    "midi_sequence.write('test.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
